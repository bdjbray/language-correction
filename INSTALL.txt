The Checker part:

PART ONE Pre-conditions:
Checker:
   There is no specific requirements for hardware.For software, only java 8 or above is required.
   You do not need to download any special packages for the checker.
   We used intellij to develop the app, so using intellij to check our program is recommended.
   But using any other IDE for java should also be fine.
Crawler:
   Could be same as checker, but if you use any other IDE, MAVEN is a recommended package which could save many processing
   from the command window.

PART TWO Supporting files:
Checker:
1. Up to now, everything we used for the checker part at this program is from the standard library.
   You do not need to download any third party libraries.
2. Simple Intro to the checker:
   Our checker is used to check the suspicious of the sentences in the txt file that you choose.
   Run the program ,you will see a java UI. Choose a txt file that you want to test.
   Press confirm and show result, you will see the result both at the GUI and at the standard output.
3. Simple intro to how the checker work:
   The checker analysis the sentences in two main ways. The first method is analyzing the sentences using the
   the sentences we get from our crawler.We break the sentences in to 2 or 3 word phrases, and check whether
   phrases for the sentence to be check exists in our file generated by the crawler.We have used the crawler
   to crawl multiple different kind of website, so it covers most common phrases, so it is relatively reliable.
   Another method to test the sentence is by checking some common errors that people always forget.For example,
   forgot to capitalize the first character of a sentence, or type more than one spaces between two words and etc.
   Suspicions equal to 100 means the sentence is most suspicious. When equal to 0, we believe it is true.
Crawler:
1. There is no extra external libraries required for version 2(in crawler branch)
2. For version 1(in crawler_twitter branch), First, getting a developer account and apply for an API key.
    https://developer.twitter.com/en/docs/basics/getting-started
   Twitter4j is a opensource API. You can download the twitter4j-4.0.7.zip from http://twitter4j.org/en/ and add twitter4j-core-4.0.7.jar to your application classpath.
   Or you can just used maven to install twitter4j api, you can just modify the pom.xml to have required frontend source code as the hyperlink mentioned. 
   (In github or bitbucket this file is already included so or you need to do is to install maven.) Plus, use maven to install twitter4j is recomended.
3.	Crawlers are used to crawl the English text in the url.There are two ways: for a simple given url,
    get the information; given a starting url and the crawling depth, it will start from the starting url,
    and keep looking for new url links in the current url to jump until the program terminates or reaches
    the required crawling depth.
4. Simple Intro to how the crawler work:
	First, the crawler saves the HTML version of the url locally and uses regular expressions to parse the text information.
    Then the text will be sorted into lines, and filter out the statement which will be more than 20 characters,
	Crawlers are used to crawl the English text in the url.There are two ways: for a simple given url,
    get the information; given a starting url and the crawling depth, it will start from the starting url,
    and keep looking for new url links in the current url to jump until the program terminates or reaches
    the required crawling depth.


PART THREE Execution:
Checker:
1. cd 'the directory you want to store the project'
2. git clone https://agile.bu.edu/bitbucket/scm/ep/group11.git
3. Open your intellij IDE or other IDE support java.
4. Open the project in IDE.
5. Setup SDK for the project.
6. go to src->Checker  and run the project.
7. Now you should have seen an java gui.
8. Type or paste the directory of the (.txt)test file to the text field.(e.i. /Users/brayb/Downloads/the_check/TestFiles/simpleTest.txt)
   (we recommend you to choose the test file we provide(TestFile/simpleTest.txt) to you first, and then run your own test file)
9. Press 'confirm' and 'show result' to see the result.
   (you can check the result both in the GUI or in the standard output)

Crawler Version 1:
1. cd 'the directory you want to store the crawler'
2. git clone the "crawler" branch
3. Open your intelliJ IDE or other IDE support java.
4. Go to file->new->project from existing source to import a MAVEN project.
5. Setup SDK for the project.
6. BE SURE TO CHECK the pom.xml to include all required dependencies, copy the following source code into pom.xml:
    <dependencies>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>3.8.1</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.twitter4j</groupId>
            <artifactId>twitter4j-core</artifactId>
            <version>4.0.0</version>
        </dependency>
        <dependency>
            <groupId>org.twitter4j</groupId>
            <artifactId>twitter4j-stream</artifactId>
            <version>4.0.0</version>
        </dependency>
    </dependencies>
7. Set two empty txt file in the root directory with the name similar name mentioned in the finalout.java and output.java.
Update the path of txt file to be valid.
8. go to src->main->java->citiaps.twitter_api
9. Open the output.java, fill in the Twitter API key that you applied.
10. Run the output.java, the terminal should show out the content being crawled.
11. Click the stop button to stop, then runs finalout.java

Crawler Version 2:
1. cd 'the directory you want to store the crawler'
2. git clone the "crawler1" branch
3. Open your intelliJ IDE or other IDE support java.
4. Go to file->new->project from existing source to import a project.
5. Setup SDK for the project.
6. go to src folder and open the crawler.java, Fill in the link URL you want, set the crawling depth n in main function and create the txt file with specified path. 
7. check whether the file you created matches the path being specified above.
7. Run the crawler.java
