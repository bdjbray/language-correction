# language-correction

## Documentation:
### Group Members:</br>
Dingjun Bian, Yuhang He, Shiyang Hu, Dingchao Wei, Hanchen Zhang</br>

---
### Description of Problem:
* This project aims to achieve a module that could check grammar of the sentences that are given.
Give the directory of the file, all the suspicious of the sentences in the file and the suspicious of the phrases in  the sentences will be checked.
Suspicious close to 100 means most suspicious, close to 0 means we believe it is correct.
* To make the checker with high accuracy, we implemented two main checking methods.
Check some common grammar error, and check whether the phrases of the sentences exists in our huge correct phrases stored. 
To guarantee the speed and correctness of the checker, we let our crawler to crawl many different kind of website.
Then we processed the data, divide the sentences into phrases, removed the duplicated phrases and stored the data in an AVLTree.
* Current problem we are facing: Although we have stored huge correct phrases, but when the sentence contains a lot specific names and locations the result might be incorrect.
We have wrote some code to avoid it, but due to time limitation there is still some more work to do.We will try to fix it soon.
---
### Description of the Implementation

* Checker  
To guarantee the speed and correctness of the checker,the checker analysis the sentences in two main methods. 
The first method is analyzing the sentences using the
the sentences we get from our crawler.We break the sentences into 2 or 3 word phrases, and check whether
   phrases for the sentence to be checked exists in our file generated by the crawler.We have used the crawler
   to crawl multiple different kind of website, so it covers most common phrases.
   We have also processed the data from the crawler by removing the duplicated or with wrong format.
   Then we stored the data in an AVLTree to improve the efficiency.
   Another method to test the sentence is by checking some basic rules that all the correct sentence should follow.For example,
   the location of the verb and noun, or type more than one spaces between two words and etc.
   We averaged the the suspicious of the phrases in the sentence, to avoid some correct phrases that we haven't covered.
   Then add the suspicious caused by violating basic grammar rules to the averaged phrases suspicious to get the final result.
   Suspicions equal to 100 means the sentence is most suspicious. When equal to 0, we believe it is right.
   The data structure we used include AVLtTree, HashMap, Set and etc.To improve searching efficiency ,we used the AVLTree to store the correct phrases, the collection of verb and nouns.During checking, the checker will utilize the AVLTree to search for phrases or words instead of txt file. We use the HashMap to store all the phrases in the sentences and the suspicious,
   so we can easily change the suspicious of the phrases.We use Set to proceed the data generated by the crawler to guarantee there is no duplicated phrase.
* GUI  
We built a java GUI for the checker.At the landing page, you shall type or paste the directory to the file that you want to test.
Then press `confirm` and `show result`, the result will be shown both at the text area in the GUI and the standard output.
so we can easily change the suspicious of the phrases.We use Set to proceed the data generated by the crawler to guarantee there is no duplicated phrase.
* Crawler  
**Currently, txt file is the media that connect the crawler and checker that storing correct phrases.** It's not realistic to achieve both formality and diversity at the same time by using simple text file. Content in government agency officials and academic website is formal but comparatively weaker in vocabulary，whereas social media is in reverse. Therefore，**this language correction have two versions of checker that works separately to serve the checker.**

---
### Features that the module already been implemented:

#### Checker -- Main Feature:

*Check the grammar of all the sentences in the text file that the user want.  
Show suspicious of all the sentences in the file, and the suspicious of phrases in the sentence.  
In a frontend Graphic User Interface, the checker taking the path of a text file as the input and listing suspicious phrases.*

Data Structure and Construction Mechanism:

  *To guarantee the speed and correctness of the checker,the checker analysis the sentences in two main methods.*

   1. The first method is analyzing the sentences using the sentences we get from our crawler.We break the sentences into two or three word phrases, store the contents of the txt file generated by the crwaler and check whether phrases for the sentence to be checked exists in the AVLTree. We have used the crawler to crawl multiple different kind of website, so it covers most common phrases. We have also processed the data from the crawler by removing the duplication or wrong format.
   
   2. Another method to test the sentence is by checking some basic rules that all the correct sentence should follow. For example, the location of the verb and noun, or type more than one spaces between two words and etc. We averaged the the suspicious of the phrases in the sentence, to mitigate the error caused by some correct phrases that we haven't covered. Then add the suspicious caused by violating basic grammar rules to the averaged phrases suspicious to get the final result. Suspicions equal to 100 means the sentence is most suspicious. When equal to 0, we believe it is completely correct.
   
   3. The data structure we used include AVLTree, HashMap, Set and etc.We first implemented an AVLTree.Then,we stored the correct phrases generated by the crwaler and the collection of noun and verb to the AVLTree, to improve the efficiency of search operation.We use the HashMap to store all the phrases in the sentences and the suspicious, so we can easily change the suspicious of the phrases. We use Set to proceed the data generated by the crawler to guarantee there is no duplicated phrase.

#### Crawler -- Main Feature: 

*Crawler's main objective is indexing web content with formal, diversified linguistic content in order to serve the checker.*

   1. Social Media Crawler:
   This crawler is derived from the twitter4j package. The main feature is Crawling (output.java) and regularizes (finaloutput.java) messages based on twitter, and storing formal phrases (Util.java). Currently, this crawler needs to be run and stop manually by clicking the running and stop button. A frontend GUI will upcoming later. </br></br>

   2. URL-based Crawler:
   For this crawler, user can choose their optional website. As the link is initialized, it first goes to an HTML parser that checks the validity of the link’s format. The parser contains a HashSet that stores the link. 
   `Downloadpage`, `readtxt`, `htmlextract`, are followed to process a “raw paragraph” from the website. Detailed descriptions toward these function shall go to see the comments from `crawler.java`. The `cutsentence` function tries to separate the sentence from the paragraph by identifying the capital letter, which should be optimized in the next sprint.
   Sentences being transferred to `output.txt`. The `filter`, in the end, grabs the output file and forms the `clause` text file that used for the checker unit. The filter mainly filtered out short sentence and the length could also be user-defined based on the `max`:
```
public static String filter(String filePath,int max) {
        StringBuilder result = new StringBuilder();
        try {
            InputStreamReader isr = new InputStreamReader(new FileInputStream(new File(filePath)),"UTF-8");
            BufferedReader bfr = new BufferedReader(isr);
            String lineTxt = null;
            while ((lineTxt = bfr.readLine()) != null) {
                if (lineTxt.length()>max)
                {result.append(lineTxt).append("\n");}
            }
            bfr.close();
        } catch (Exception e) {
            e.printStackTrace();
        }
        return result.toString();
    }
``` 
---
## Code
* The Checker is in the main branch and the crawler is in the crawler branch.
* For the checker, we have provided the two test files,they were in the TestFiles directory called largerTest.txt and simpleTest.txt
(we recommend you to use these two files to check our checker first, then use your own file you want)
* The installation guide is at part three of our INSTALL.txt 
## Work breakdown
Dingjun Bian: worked on the checker, GUI and documentation  
Yuhang He: worked on the checker  
Shiyang Hu: worked on the crawler and documentation  
Dingchao Wei: worked on the crawler and documentation  
Hanchen Zhang: helped both side,work on testing and documentation 

















# language-correction


## Sprint one Demonstration
Type or copy the directory of the file to the text field and press  `confirm`.</br>
You may use the simpleTest.txt that I provided.</br>
![image](https://github.com/bdjbray/language-correction/blob/master/images/Screen%20Shot%202020-04-05%20at%205.52.49%20PM.png)

Press the `show result` button to see the suspicions of the sentences in the file.</br>
![image](https://github.com/bdjbray/language-correction/blob/master/images/Screen%20Shot%202020-04-05%20at%206.15.53%20PM.png)
